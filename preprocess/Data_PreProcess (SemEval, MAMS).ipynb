{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:05.115565Z",
     "start_time": "2023-01-10T14:48:03.365770Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:05.128645Z",
     "start_time": "2023-01-10T14:48:05.117904Z"
    }
   },
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words(\"english\")\n",
    "def text_process(text):\n",
    "    text = \" \".join([w for w in text if w not in all_stopwords])\n",
    "    return text.strip('.').strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:07.726773Z",
     "start_time": "2023-01-10T14:48:06.970182Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"../data/raw/SemEval-2014-Task-4-REST/SemEval'14-ABSA-TrainData_v2 & AnnotationGuidelines/Restaurants_Train_v2.xml\") as f:\n",
    "    xml = f.read()\n",
    "    \n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "sentences = soup.find_all(\"sentence\")\n",
    "IDs = []\n",
    "texts = []\n",
    "cats = []\n",
    "pols = []\n",
    "\n",
    "for s in sentences:\n",
    "    items = s.find_all(\"aspectcategory\")\n",
    "    for i in items:\n",
    "        IDs.append(s.attrs['id'])\n",
    "        texts.append(s.find(\"text\").text)\n",
    "        cats.append(i.attrs['category'])\n",
    "        pols.append(i.attrs['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:08.304320Z",
     "start_time": "2023-01-10T14:48:08.289781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3713, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_14_train = pd.DataFrame({\"ID\":IDs, \"Text\":texts, \"Aspect\":cats, \"Polarity\":pols})\n",
    "rest_14_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:51.242457Z",
     "start_time": "2023-01-10T14:48:51.042435Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"../data/raw/SemEval-2014-Task-4-REST/ABSA_Gold_TestData/Restaurants_Test_Gold.xml\") as f:\n",
    "    xml = f.read()\n",
    "\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "sentences = soup.find_all(\"sentence\")\n",
    "IDs = []\n",
    "texts = []\n",
    "cats = []\n",
    "pols = []\n",
    "\n",
    "for s in sentences:\n",
    "    items = s.find_all(\"aspectcategory\")\n",
    "    for i in items:\n",
    "        IDs.append(s.attrs['id'])\n",
    "        texts.append(s.find(\"text\").text)\n",
    "        cats.append(i.attrs['category'])\n",
    "        pols.append(i.attrs['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:52.348822Z",
     "start_time": "2023-01-10T14:48:52.333803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_14_test = pd.DataFrame({\"ID\":IDs, \"Text\":texts, \"Aspect\":cats, \"Polarity\":pols})\n",
    "rest_14_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:55.961911Z",
     "start_time": "2023-01-10T14:48:53.743530Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert data to 1 vs multi, one sentence for multiple aspects即一个句子对应多个aspects\n",
    "def f(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    elif x == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def get_info(df):\n",
    "    IDs = df['ID'].unique()\n",
    "    big = []\n",
    "    for ID in IDs:\n",
    "        result = [-2, -2, -2, -2, -2]\n",
    "        order = ['service', 'food', 'anecdotes/miscellaneous', 'price', 'ambience']\n",
    "        item = df[df['ID'] == ID]\n",
    "        for index, row in item.iterrows():\n",
    "            result[order.index(row['Aspect'])] = f(row['Polarity'])\n",
    "        result += [ID, item['Text'].values[0]]\n",
    "        big.append(result)\n",
    "    res = pd.DataFrame(big)\n",
    "    res.columns = order + ['ID', 'Text']\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "rest_14_train = get_info(rest_14_train)\n",
    "rest_14_test = get_info(rest_14_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:48:56.746687Z",
     "start_time": "2023-01-10T14:48:56.733686Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate overall rating\n",
    "# most samples only has one aspect\n",
    "# we use majority score here\n",
    "\n",
    "def get_overall(df):\n",
    "    overall = []\n",
    "    for item in df.values:\n",
    "        item = item[:5]\n",
    "        v = sum([i for i in item if i != -2])\n",
    "        if v >= 1:\n",
    "            overall.append(2)\n",
    "        elif v == 0:\n",
    "            overall.append(1)\n",
    "        else:\n",
    "            overall.append(0)\n",
    "    \n",
    "    return overall\n",
    "\n",
    "rest_14_train['Overall'] = get_overall(rest_14_train)\n",
    "rest_14_test['Overall'] = get_overall(rest_14_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:49:00.352410Z",
     "start_time": "2023-01-10T14:48:59.924184Z"
    }
   },
   "outputs": [],
   "source": [
    "rest_14_train['process_review'] = rest_14_train['Text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)\n",
    "rest_14_test['process_review'] = rest_14_test['Text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:51:39.527157Z",
     "start_time": "2023-01-10T14:51:39.511519Z"
    }
   },
   "outputs": [],
   "source": [
    "rest_14_train['n_of_tokens'] = rest_14_train['process_review'].str.split().apply(lambda x:len(x))\n",
    "rest_14_test['n_of_tokens'] = rest_14_test['process_review'].str.split().apply(lambda x:len(x))\n",
    "\n",
    "rest_14_train = rest_14_train[rest_14_train['n_of_tokens']>0]\n",
    "rest_14_test = rest_14_test[rest_14_test['n_of_tokens']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:53:21.991586Z",
     "start_time": "2023-01-10T14:53:21.969604Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\python3.6\\lib\\site-packages\\pandas\\core\\frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2734, 10), (304, 10), (800, 10))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dev set\n",
    "rest_14_dev = rest_14_train.sample(frac=0.1, random_state=1)\n",
    "rest_14_train.drop(rest_14_dev.index, axis=0, inplace=True)\n",
    "\n",
    "rest_14_train.shape, rest_14_dev.shape, rest_14_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:53:56.825788Z",
     "start_time": "2023-01-10T14:53:56.783511Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate corpus for ABAE\n",
    "all_reviews = rest_14_train['process_review'].values.tolist()\n",
    "with open(\"../data/processed/rest_14_comments.txt\", 'w', encoding='utf-8') as f:\n",
    "    for r in all_reviews:\n",
    "        f.write(str(r))\n",
    "        f.write('\\n')\n",
    "        \n",
    "rest_14_train.to_csv(r\"../data/processed/rest_14_train.csv\", index=False)\n",
    "rest_14_dev.to_csv(r\"../data/processed/rest_14_dev.csv\", index=False)\n",
    "rest_14_test.to_csv(r\"../data/processed/rest_14_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:53:58.993212Z",
     "start_time": "2023-01-10T14:53:58.612561Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"../data/raw/SemEval-2015-Task-12-REST/ABSA15_RestaurantsTrain/ABSA-15_Restaurants_Train_Final.xml\") as f:\n",
    "    xml = f.read()\n",
    "\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "sentences = soup.find_all(\"sentence\")\n",
    "IDs = []\n",
    "texts = []\n",
    "cats = []\n",
    "pols = []\n",
    "\n",
    "for s in sentences:\n",
    "    items = s.find_all(\"opinion\")\n",
    "    for i in items:\n",
    "        IDs.append(s.attrs['id'])\n",
    "        texts.append(s.find(\"text\").text)\n",
    "        cats.append(i.attrs['category'])\n",
    "        pols.append(i.attrs['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:53:59.743580Z",
     "start_time": "2023-01-10T14:53:59.734526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1654, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_15_train = pd.DataFrame({\"ID\":IDs, \"Text\":texts, \"Aspect\":cats, \"Polarity\":pols})\n",
    "rest_15_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:54:00.955796Z",
     "start_time": "2023-01-10T14:54:00.821971Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"../data/raw/SemEval-2015-Task-12-REST/ABSA15_Restaurants_Test.xml\", encoding='utf-8') as f:\n",
    "    xml = f.read()\n",
    "\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "sentences = soup.find_all(\"sentence\")\n",
    "IDs = []\n",
    "texts = []\n",
    "cats = []\n",
    "pols = []\n",
    "\n",
    "for s in sentences:\n",
    "    items = s.find_all(\"opinion\")\n",
    "    for i in items:\n",
    "        IDs.append(s.attrs['id'])\n",
    "        texts.append(s.find(\"text\").text)\n",
    "        cats.append(i.attrs['category'])\n",
    "        pols.append(i.attrs['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:54:01.659263Z",
     "start_time": "2023-01-10T14:54:01.646790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(845, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_15_test = pd.DataFrame({\"ID\":IDs, \"Text\":texts, \"Aspect\":cats, \"Polarity\":pols})\n",
    "rest_15_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:54:01.959076Z",
     "start_time": "2023-01-10T14:54:01.946091Z"
    }
   },
   "outputs": [],
   "source": [
    "# rest 14直接是aspect，但15，16出现了category和aspect，所以需多一个处理\n",
    "def f(x):\n",
    "    return x.split(\"#\")[0]\n",
    "\n",
    "rest_15_train['Aspect_Category'] = rest_15_train['Aspect'].apply(lambda x:f(x))\n",
    "rest_15_test['Aspect_Category'] = rest_15_test['Aspect'].apply(lambda x:f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:54:03.493209Z",
     "start_time": "2023-01-10T14:54:02.782845Z"
    }
   },
   "outputs": [],
   "source": [
    "# 扭转数据集至1对多\n",
    "# 即一个句子对应多个aspect（如果有多个的话）\n",
    "def f(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    elif x == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def get_info(df):\n",
    "    IDs = df['ID'].unique()\n",
    "    big = []\n",
    "    for ID in IDs:\n",
    "        result = [-2, -2, -2, -2, -2, -2]\n",
    "        order = ['RESTAURANT', 'SERVICE', 'FOOD', 'DRINKS', 'AMBIENCE', 'LOCATION']\n",
    "        item = df[df['ID'] == ID]\n",
    "        for index, row in item.iterrows():\n",
    "            result[order.index(row['Aspect_Category'])] = f(row['Polarity'])\n",
    "        result += [ID, item['Text'].values[0]]\n",
    "        big.append(result)\n",
    "    res = pd.DataFrame(big)\n",
    "    res.columns = order + ['ID', 'Text']\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "rest_15_train = get_info(rest_15_train)\n",
    "rest_15_test = get_info(rest_15_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:54:04.074473Z",
     "start_time": "2023-01-10T14:54:04.058961Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成overall rating\n",
    "# 大部分都仅有一个aspect，这里我们就把非-2的项加起来作为overall\n",
    "def get_overall(df):\n",
    "    overall = []\n",
    "    for item in df.values:\n",
    "        item = item[:6]\n",
    "        v = sum([i for i in item if i != -2])\n",
    "        if v >= 1:\n",
    "            overall.append(2)\n",
    "        elif v == 0:\n",
    "            overall.append(1)\n",
    "        else:\n",
    "            overall.append(0)\n",
    "    \n",
    "    return overall\n",
    "\n",
    "rest_15_train['Overall'] = get_overall(rest_15_train)\n",
    "rest_15_test['Overall'] = get_overall(rest_15_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:54:05.790157Z",
     "start_time": "2023-01-10T14:54:05.603137Z"
    }
   },
   "outputs": [],
   "source": [
    "# 文本处理\n",
    "rest_15_train['process_review'] = rest_15_train['Text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)\n",
    "rest_15_test['process_review'] = rest_15_test['Text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:01.071280Z",
     "start_time": "2023-01-10T14:55:01.050552Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把文本处理后为0的直接删除\n",
    "rest_15_train['n_of_tokens'] = rest_15_train['process_review'].str.split().apply(lambda x:len(x))\n",
    "rest_15_test['n_of_tokens'] = rest_15_test['process_review'].str.split().apply(lambda x:len(x))\n",
    "\n",
    "rest_15_train = rest_15_train[rest_15_train['n_of_tokens']>0]\n",
    "rest_15_test = rest_15_test[rest_15_test['n_of_tokens']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:04.898281Z",
     "start_time": "2023-01-10T14:55:04.885107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1007, 11), (112, 11), (582, 11))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分出dev set\n",
    "rest_15_dev = rest_15_train.sample(frac=0.1, random_state=1)\n",
    "rest_15_train.drop(rest_15_dev.index, axis=0, inplace=True)\n",
    "\n",
    "rest_15_train.shape, rest_15_dev.shape, rest_15_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:10.319833Z",
     "start_time": "2023-01-10T14:55:10.291490Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成ABAE需要的语料\n",
    "all_reviews = rest_15_train['process_review'].values.tolist()\n",
    "with open(\"../data/processed/rest_15_comments.txt\", 'w', encoding='utf-8') as f:\n",
    "    for r in all_reviews:\n",
    "        f.write(str(r))\n",
    "        f.write('\\n')\n",
    "        \n",
    "rest_15_train.to_csv(r\"../data/processed/rest_15_train.csv\", index=False)\n",
    "rest_15_dev.to_csv(r\"../data/processed/rest_15_dev.csv\", index=False)\n",
    "rest_15_test.to_csv(r\"../data/processed/rest_15_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T03:34:51.126306Z",
     "start_time": "2023-01-01T03:34:51.112741Z"
    }
   },
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:18.618625Z",
     "start_time": "2023-01-10T14:55:18.244633Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"../data/raw/SemEval-2016-Task-5-REST-SB1/ABSA16_Restaurants_Train_SB1_v2.xml\", encoding='utf-8') as f:\n",
    "    xml = f.read()\n",
    "\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "sentences = soup.find_all(\"sentence\")\n",
    "IDs = []\n",
    "texts = []\n",
    "cats = []\n",
    "pols = []\n",
    "\n",
    "for s in sentences:\n",
    "    items = s.find_all(\"opinion\")\n",
    "    for i in items:\n",
    "        IDs.append(s.attrs['id'])\n",
    "        texts.append(s.find(\"text\").text)\n",
    "        cats.append(i.attrs['category'])\n",
    "        pols.append(i.attrs['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:19.264265Z",
     "start_time": "2023-01-10T14:55:19.256119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2507, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_16_train = pd.DataFrame({\"ID\":IDs, \"Text\":texts, \"Aspect\":cats, \"Polarity\":pols})\n",
    "rest_16_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:20.258102Z",
     "start_time": "2023-01-10T14:55:20.114454Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"../data/raw/SemEval-2016-Task-5-REST-SB1/EN_REST_SB1_TEST.xml\", encoding='utf-8') as f:\n",
    "    xml = f.read()\n",
    "\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "sentences = soup.find_all(\"sentence\")\n",
    "IDs = []\n",
    "texts = []\n",
    "cats = []\n",
    "pols = []\n",
    "\n",
    "for s in sentences:\n",
    "    items = s.find_all(\"opinion\")\n",
    "    for i in items:\n",
    "        IDs.append(s.attrs['id'])\n",
    "        texts.append(s.find(\"text\").text)\n",
    "        cats.append(i.attrs['category'])\n",
    "        pols.append(i.attrs['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:21.119029Z",
     "start_time": "2023-01-10T14:55:21.111035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_16_test = pd.DataFrame({\"ID\":IDs, \"Text\":texts, \"Aspect\":cats, \"Polarity\":pols})\n",
    "rest_16_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:21.564095Z",
     "start_time": "2023-01-10T14:55:21.534925Z"
    }
   },
   "outputs": [],
   "source": [
    "# rest 14直接是aspect，但15，16出现了category和aspect，所以需多一个处理\n",
    "def f(x):\n",
    "    return x.split(\"#\")[0]\n",
    "\n",
    "rest_16_train['Aspect_Category'] = rest_16_train['Aspect'].apply(lambda x:f(x))\n",
    "rest_16_test['Aspect_Category'] = rest_16_test['Aspect'].apply(lambda x:f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:26.696404Z",
     "start_time": "2023-01-10T14:55:25.635644Z"
    }
   },
   "outputs": [],
   "source": [
    "# 扭转数据集至1对多\n",
    "# 即一个句子对应多个aspect（如果有多个的话）\n",
    "def f(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    elif x == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def get_info(df):\n",
    "    IDs = df['ID'].unique()\n",
    "    big = []\n",
    "    for ID in IDs:\n",
    "        result = [-2, -2, -2, -2, -2, -2]\n",
    "        order = ['RESTAURANT', 'SERVICE', 'FOOD', 'DRINKS', 'AMBIENCE', 'LOCATION']\n",
    "        item = df[df['ID'] == ID]\n",
    "        for index, row in item.iterrows():\n",
    "            result[order.index(row['Aspect_Category'])] = f(row['Polarity'])\n",
    "        result += [ID, item['Text'].values[0]]\n",
    "        big.append(result)\n",
    "    res = pd.DataFrame(big)\n",
    "    res.columns = order + ['ID', 'Text']\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "rest_16_train = get_info(rest_16_train)\n",
    "rest_16_test = get_info(rest_16_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:26.718991Z",
     "start_time": "2023-01-10T14:55:26.698694Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成overall rating\n",
    "# 大部分都仅有一个aspect，这里我们就把非-2的项加起来作为overall\n",
    "def get_overall(df):\n",
    "    overall = []\n",
    "    for item in df.values:\n",
    "        item = item[:6]\n",
    "        v = sum([i for i in item if i != -2])\n",
    "        if v >= 1:\n",
    "            overall.append(2)\n",
    "        elif v == 0:\n",
    "            overall.append(1)\n",
    "        else:\n",
    "            overall.append(0)\n",
    "    \n",
    "    return overall\n",
    "\n",
    "rest_16_train['Overall'] = get_overall(rest_16_train)\n",
    "rest_16_test['Overall'] = get_overall(rest_16_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:28.102349Z",
     "start_time": "2023-01-10T14:55:27.859664Z"
    }
   },
   "outputs": [],
   "source": [
    "# 文本处理\n",
    "rest_16_train['process_review'] = rest_16_train['Text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)\n",
    "rest_16_test['process_review'] = rest_16_test['Text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:46.546381Z",
     "start_time": "2023-01-10T14:55:46.526915Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把文本处理后为0的直接删除\n",
    "rest_16_train['n_of_tokens'] = rest_16_train['process_review'].str.split().apply(lambda x:len(x))\n",
    "rest_16_test['n_of_tokens'] = rest_16_test['process_review'].str.split().apply(lambda x:len(x))\n",
    "\n",
    "rest_16_train = rest_16_train[rest_16_train['n_of_tokens']>0]\n",
    "rest_16_test = rest_16_test[rest_16_test['n_of_tokens']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:50.008607Z",
     "start_time": "2023-01-10T14:55:49.988591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1535, 11), (171, 11), (587, 11))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分出dev set\n",
    "rest_16_dev = rest_16_train.sample(frac=0.1, random_state=1)\n",
    "rest_16_train.drop(rest_16_dev.index, axis=0, inplace=True)\n",
    "\n",
    "rest_16_train.shape, rest_16_dev.shape, rest_16_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:54.508906Z",
     "start_time": "2023-01-10T14:55:54.127614Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成ABAE需要的语料\n",
    "all_reviews = rest_16_train['process_review'].values.tolist()\n",
    "with open(\"../data/processed/rest_16_comments.txt\", 'w', encoding='utf-8') as f:\n",
    "    for r in all_reviews:\n",
    "        f.write(str(r))\n",
    "        f.write('\\n')\n",
    "        \n",
    "rest_16_train.to_csv(r\"../data/processed/rest_16_train.csv\", index=False)\n",
    "rest_16_dev.to_csv(r\"../data/processed/rest_16_dev.csv\", index=False)\n",
    "rest_16_test.to_csv(r\"../data/processed/rest_16_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:57.711374Z",
     "start_time": "2023-01-10T14:55:57.127970Z"
    }
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    with open(path) as f:\n",
    "        xml = f.read()\n",
    "    soup = BeautifulSoup(xml, 'xml')\n",
    "    return soup\n",
    "        \n",
    "train_soup = read(\"../data/raw/MAMS/train.xml\")\n",
    "val_soup = read(\"../data/raw/MAMS/val.xml\")\n",
    "test_soup = read(\"../data/raw/MAMS/test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:58.422711Z",
     "start_time": "2023-01-10T14:55:58.412700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将xml变为dataframe\n",
    "def process(soup, split='train'):\n",
    "    def pol_2_sco(pol):\n",
    "        if pol == 'neutral':\n",
    "            return 0\n",
    "        elif pol == 'negative':\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    values = []\n",
    "    for item in soup.find_all(\"sentence\"):\n",
    "        dic = {'ambience':-2, 'food':-2, 'menu':-2, 'miscellaneous':-2, 'place':-2, 'price':-2, 'service':-2, 'staff':-2}\n",
    "        groups = item.find_all(\"aspectCategory\")\n",
    "        for g in groups:\n",
    "            dic[g.attrs['category']] = pol_2_sco(g.attrs['polarity'])\n",
    "\n",
    "        lst = [item.find(\"text\").text] + [split] + list(dic.values())\n",
    "        values.append(lst)\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:55:59.852972Z",
     "start_time": "2023-01-10T14:55:59.577174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3149, 400, 400)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values = process(train_soup, split='train')\n",
    "val_values = process(val_soup, split='val')\n",
    "test_values = process(test_soup, split='test')\n",
    "\n",
    "len(train_values), len(val_values), len(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:56:00.536580Z",
     "start_time": "2023-01-10T14:56:00.517582Z"
    }
   },
   "outputs": [],
   "source": [
    "values = train_values + val_values + test_values\n",
    "df = pd.DataFrame(values)\n",
    "df.columns = ['text', 'split', 'ambience', 'food', 'menu', 'miscellaneous', 'place', 'price', 'service', 'staff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:56:01.607912Z",
     "start_time": "2023-01-10T14:56:01.588965Z"
    }
   },
   "outputs": [],
   "source": [
    "# mams本来就长相很好，不需要扭转\n",
    "# 生成overall rating\n",
    "# 虽然不像rest，mams大部分都有两个aspect，但这里处理方法还是一样。把非-2的项加起来作为overall\n",
    "def get_overall(df):\n",
    "    overall = []\n",
    "    for item in df.values:\n",
    "        item = item[2:]\n",
    "        v = sum([i for i in item if i != -2])\n",
    "        if v >= 1:\n",
    "            overall.append(2)\n",
    "        elif v == 0:\n",
    "            overall.append(1)\n",
    "        else:\n",
    "            overall.append(0)\n",
    "    \n",
    "    return overall\n",
    "\n",
    "df['Overall'] = get_overall(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:56:05.202891Z",
     "start_time": "2023-01-10T14:56:04.623714Z"
    }
   },
   "outputs": [],
   "source": [
    "# 文本处理\n",
    "df['process_review'] = df['text'].str.lower().replace(\"\"\"[;:)\"’!.?,‘”“(><_'-+/]\"\"\", \"\", regex=True).apply(word_tokenize).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:56:49.181853Z",
     "start_time": "2023-01-10T14:56:49.162434Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把文本处理后为0的直接删除\n",
    "df['n_of_tokens'] = df['process_review'].str.split().apply(lambda x:len(x))\n",
    "df = df[df['n_of_tokens']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T14:56:54.420722Z",
     "start_time": "2023-01-10T14:56:54.378204Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成ABAE需要的语料\n",
    "all_reviews = df[df['split'] == 'train']['process_review'].values.tolist()\n",
    "with open(\"../data/processed/mams_comments.txt\", 'w', encoding='utf-8') as f:\n",
    "    for r in all_reviews:\n",
    "        f.write(str(r))\n",
    "        f.write('\\n')\n",
    "        \n",
    "\n",
    "df.to_csv(r\"../data/processed/mams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
